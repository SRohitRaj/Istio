#
# addon tracing configuration
#
tracing:
  enabled: false

  provider: jaeger
  nodeSelector: {}
  tolerations: []

  # Specify the pod anti-affinity that allows you to constrain which nodes
  # your pod is eligible to be scheduled based on labels on pods that are
  # already running on the node rather than based on labels on nodes.
  # There are currently two types of anti-affinity:
  #    "requiredDuringSchedulingIgnoredDuringExecution"
  #    "preferredDuringSchedulingIgnoredDuringExecution"
  # which denote "hard" vs. "soft" requirements, you can define your values
  # in "podAntiAffinityLabelSelector" and "podAntiAffinityTermLabelSelector"
  # correspondingly.
  # For example:
  # podAntiAffinityLabelSelector:
  # - key: security
  #   operator: In
  #   values: S1,S2
  #   topologyKey: "kubernetes.io/hostname"
  # This pod anti-affinity rule says that the pod requires not to be scheduled
  # onto a node if that node is already running a pod with label having key
  # "security" and value "S1".
  podAntiAffinityLabelSelector: []
  podAntiAffinityTermLabelSelector: []

  contextPath: ""


  jaeger:
    hub: docker.io/jaegertracing
    image: all-in-one
    tag: 1.18
    memory:
      max_traces: 50000
    resources: {}
    # spanStorageType value can be "memory" and "badger" for all-in-one image
    spanStorageType: badger
    persist: false
    storageClassName: ""
    accessMode: ReadWriteMany
    podAnnotations: {}

  zipkin:
    hub: docker.io/openzipkin
    image: zipkin-slim
    tag: 2.20.0
    probeStartupDelay: 10
    livenessProbeStartupDelay: 200
    queryPort: 9411
    resources:
      limits:
        cpu: 1000m
        memory: 2048Mi
      requests:
        cpu: 150m
        memory: 900Mi
    javaOptsHeap: 700
    # From: https://github.com/openzipkin/zipkin/blob/master/zipkin-server/src/main/resources/zipkin-server-shared.yml#L51
    # Maximum number of spans to keep in memory.  When exceeded, oldest traces (and their spans) will be purged.
    # A safe estimate is 1K of memory per span (each span with 2 annotations + 1 binary annotation), plus
    # 100 MB for a safety buffer.  You'll need to verify in your own environment.
    maxSpans: 500000
    node:
      cpus: 2
    podAnnotations: {}

  opencensus:
    hub: docker.io/omnition
    tag: 0.1.9
    resources:
      limits:
        cpu: 1
        memory: 2Gi
      requests:
        cpu: 200m
        memory: 400Mi
    exporters:
      stackdriver:
        enable_tracing: true
    podAnnotations: {}

  service:
    annotations: {}
    name: http-query
    type: ClusterIP
    externalPort: 80

global:
  # Specify pod scheduling arch(amd64, ppc64le, s390x) and weight as follows:
  #   0 - Never scheduled
  #   1 - Least preferred
  #   2 - No preference
  #   3 - Most preferred
  arch:
    amd64: 2
    s390x: 2
    ppc64le: 2

  # Default node selector to be applied to all deployments so that all pods can be
  # constrained to run a particular nodes. Each component can overwrite these default
  # values by adding its node selector block in the relevant section below and setting
  # the desired values.
  defaultNodeSelector: {}

  # Default node tolerations to be applied to all deployments so that all pods can be
  # scheduled to a particular nodes with matching taints. Each component can overwrite
  # these default values by adding its tolerations block in the relevant section below
  # and setting the desired values.
  # Configure this field in case that all pods of Istio control plane are expected to
  # be scheduled to particular nodes with specified taints.
  defaultTolerations: []

  # A minimal set of requested resources to applied to all deployments so that
  # Horizontal Pod Autoscaler will be able to function (if set).
  # Each component can overwrite these default values by adding its own resources
  # block in the relevant section below and setting the desired resources values.
  defaultResources:
    requests:
      cpu: 10m
    #   memory: 128Mi
    # limits:
    #   cpu: 100m
    #   memory: 128Mi

  # Specify image pull policy if default behavior isn't desired.
  # Default behavior: latest images will be Always else IfNotPresent.
  imagePullPolicy: ""

  # ImagePullSecrets for all ServiceAccount, list of secrets in the same namespace
  # to use for pulling any images in pods that reference this ServiceAccount.
  # For components that don't use ServiceAccounts (i.e. grafana, servicegraph, tracing)
  # ImagePullSecrets will be added to the corresponding Deployment(StatefulSet) objects.
  # Must be set for any cluster configured with private docker registry.
  imagePullSecrets: []
  # - private-registry-key

  # Kubernetes >=v1.11.0 will create two PriorityClass, including system-cluster-critical and
  # system-node-critical, it is better to configure this in order to make sure your Istio pods
  # will not be killed because of low priority class.
  # Refer to https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass
  # for more detail.
  priorityClassName: ""
