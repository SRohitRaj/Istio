# Derived from https://github.com/knative/serving/releases/download/v0.11.0/serving.yaml
# CRDs have been split into a different file to make installation easier
apiVersion: v1
kind: Namespace
metadata:
  labels:
    istio-injection: enabled
    serving.knative.dev/release: "v0.11.0"
  name: knative-serving
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    duck.knative.dev/addressable: "true"
    serving.knative.dev/release: "v0.11.0"
  name: knative-serving-addressable-resolver
rules:
- apiGroups:
  - serving.knative.dev
  resources:
  - routes
  - routes/status
  - services
  - services/status
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    autoscaling.knative.dev/metric-provider: custom-metrics
    serving.knative.dev/release: "v0.11.0"
  name: custom-metrics-server-resources
rules:
- apiGroups:
  - custom.metrics.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    rbac.authorization.k8s.io/aggregate-to-admin: "true"
    serving.knative.dev/release: "v0.11.0"
  name: knative-serving-namespaced-admin
rules:
- apiGroups:
  - serving.knative.dev
  - networking.internal.knative.dev
  - autoscaling.internal.knative.dev
  - caching.internal.knative.dev
  resources:
  - '*'
  verbs:
  - '*'
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    rbac.authorization.k8s.io/aggregate-to-edit: "true"
    serving.knative.dev/release: "v0.11.0"
  name: knative-serving-namespaced-edit
rules:
- apiGroups:
  - serving.knative.dev
  - networking.internal.knative.dev
  - autoscaling.internal.knative.dev
  - caching.internal.knative.dev
  resources:
  - '*'
  verbs:
  - create
  - update
  - patch
  - delete
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    rbac.authorization.k8s.io/aggregate-to-view: "true"
    serving.knative.dev/release: "v0.11.0"
  name: knative-serving-namespaced-view
rules:
- apiGroups:
  - serving.knative.dev
  - networking.internal.knative.dev
  - autoscaling.internal.knative.dev
  - caching.internal.knative.dev
  resources:
  - '*'
  verbs:
  - get
  - list
  - watch

---
aggregationRule:
  clusterRoleSelectors:
  - matchLabels:
      serving.knative.dev/controller: "true"
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: knative-serving-admin
rules: []
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    serving.knative.dev/controller: "true"
    serving.knative.dev/release: "v0.11.0"
  name: knative-serving-core
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - namespaces
  - secrets
  - configmaps
  - endpoints
  - services
  - events
  - serviceaccounts
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
- apiGroups:
  - ""
  resources:
  - endpoints/restricted
  verbs:
  - create
- apiGroups:
  - apps
  resources:
  - deployments
  - deployments/finalizers
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - mutatingwebhookconfigurations
  - validatingwebhookconfigurations
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
- apiGroups:
  - autoscaling
  resources:
  - horizontalpodautoscalers
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
- apiGroups:
  - serving.knative.dev
  - autoscaling.internal.knative.dev
  - networking.internal.knative.dev
  resources:
  - '*'
  - '*/status'
  - '*/finalizers'
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - deletecollection
  - patch
  - watch
- apiGroups:
  - caching.internal.knative.dev
  resources:
  - images
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    duck.knative.dev/podspecable: "true"
    serving.knative.dev/release: "v0.11.0"
  name: knative-serving-podspecable-binding
rules:
- apiGroups:
  - serving.knative.dev
  resources:
  - configurations
  - services
  verbs:
  - list
  - watch
  - patch

---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: controller
  namespace: knative-serving

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    autoscaling.knative.dev/metric-provider: custom-metrics
    serving.knative.dev/release: "v0.11.0"
  name: custom-metrics:system:auth-delegator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
- kind: ServiceAccount
  name: controller
  namespace: knative-serving

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    autoscaling.knative.dev/metric-provider: custom-metrics
    serving.knative.dev/release: "v0.11.0"
  name: hpa-controller-custom-metrics
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: custom-metrics-server-resources
subjects:
- kind: ServiceAccount
  name: horizontal-pod-autoscaler
  namespace: kube-system

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: knative-serving-controller-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: knative-serving-admin
subjects:
- kind: ServiceAccount
  name: controller
  namespace: knative-serving

---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: activator
    serving.knative.dev/release: "v0.11.0"
  name: activator-service
  namespace: knative-serving
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 8012
  - name: http2
    port: 81
    protocol: TCP
    targetPort: 8013
  - name: http-metrics
    port: 9090
    protocol: TCP
    targetPort: 9090
  selector:
    app: activator
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: controller
    serving.knative.dev/release: "v0.11.0"
  name: controller
  namespace: knative-serving
spec:
  ports:
  - name: http-metrics
    port: 9090
    protocol: TCP
    targetPort: 9090
  selector:
    app: controller

---
apiVersion: v1
kind: Service
metadata:
  labels:
    role: webhook
    serving.knative.dev/release: "v0.11.0"
  name: webhook
  namespace: knative-serving
spec:
  ports:
  - name: https-webhook
    port: 443
    targetPort: 8443
  selector:
    role: webhook
---
#apiVersion: admissionregistration.k8s.io/v1beta1
#kind: MutatingWebhookConfiguration
#metadata:
#  labels:
#    serving.knative.dev/release: "v0.11.0"
#  name: webhook.serving.knative.dev
#webhooks:
#- admissionReviewVersions:
#  - v1beta1
#  clientConfig:
#    service:
#      name: webhook
#      namespace: knative-serving
#  failurePolicy: Fail
#  name: webhook.serving.knative.dev
#---
#apiVersion: admissionregistration.k8s.io/v1beta1
#kind: ValidatingWebhookConfiguration
#metadata:
#  labels:
#    serving.knative.dev/release: "v0.11.0"
#  name: validation.webhook.serving.knative.dev
#webhooks:
#- admissionReviewVersions:
#  - v1beta1
#  clientConfig:
#    service:
#      name: webhook
#      namespace: knative-serving
#  failurePolicy: Fail
#  name: validation.webhook.serving.knative.dev
#---
#apiVersion: admissionregistration.k8s.io/v1beta1
#kind: ValidatingWebhookConfiguration
#metadata:
#  labels:
#    serving.knative.dev/release: "v0.11.0"
#  name: config.webhook.serving.knative.dev
#webhooks:
#- admissionReviewVersions:
#  - v1beta1
#  clientConfig:
#    service:
#      name: webhook
#      namespace: knative-serving
#  failurePolicy: Fail
#  name: config.webhook.serving.knative.dev
#  namespaceSelector:
#    matchExpressions:
#    - key: serving.knative.dev/release
#      operator: Exists
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: webhook-certs
  namespace: knative-serving

---
apiVersion: caching.internal.knative.dev/v1alpha1
kind: Image
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: queue-proxy
  namespace: knative-serving
spec:
  image: gcr.io/knative-releases/knative.dev/serving/cmd/queue@sha256:077d82a8f7b3f8c645e95abdf20acf1f1c5ea4d2215aa43ac707920914db5cf8

---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: activator
  namespace: knative-serving
spec:
  selector:
    matchLabels:
      app: activator
      role: activator
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
        sidecar.istio.io/inject: "true"
      labels:
        app: activator
        role: activator
        serving.knative.dev/release: "v0.11.0"
    spec:
      containers:
      - env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: METRICS_DOMAIN
          value: knative.dev/internal/serving
        image: gcr.io/knative-releases/knative.dev/serving/cmd/activator@sha256:48192304c0d6bbebc04ccf23bc1447f6b2e84a98ec65fcf9f4c862f948653eec
        livenessProbe:
          httpGet:
            httpHeaders:
            - name: k-kubelet-probe
              value: activator
            path: /healthz
            port: 8012
        name: activator
        ports:
        - containerPort: 8012
          name: http1
        - containerPort: 8013
          name: h2c
        - containerPort: 9090
          name: metrics
        - containerPort: 8008
          name: profiling
        readinessProbe:
          httpGet:
            httpHeaders:
            - name: k-kubelet-probe
              value: activator
            path: /healthz
            port: 8012
        resources:
          limits:
            cpu: 1000m
            memory: 600Mi
          requests:
            cpu: 30m
            memory: 60Mi
        securityContext:
          allowPrivilegeEscalation: false
      serviceAccountName: controller
      terminationGracePeriodSeconds: 300
---
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: activator
  namespace: knative-serving
spec:
  maxReplicas: 20
  metrics:
  - resource:
      name: cpu
      targetAverageUtilization: 100
    type: Resource
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: activator
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    autoscaling.knative.dev/autoscaler-provider: hpa
    serving.knative.dev/release: "v0.11.0"
  name: autoscaler-hpa
  namespace: knative-serving
spec:
  replicas: 1
  selector:
    matchLabels:
      app: autoscaler-hpa
  template:
    metadata:
      annotations:
        sidecar.istio.io/inject: "false"
      labels:
        app: autoscaler-hpa
        serving.knative.dev/release: "v0.11.0"
    spec:
      containers:
      - env:
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: METRICS_DOMAIN
          value: knative.dev/serving
        image: gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler-hpa@sha256:4f1b95f20e49056578dc93a465de43d3421711e5043b95897d8091cebe561b12
        name: autoscaler-hpa
        ports:
        - containerPort: 9090
          name: metrics
        - containerPort: 8008
          name: profiling
        resources:
          limits:
            cpu: 1000m
            memory: 1000Mi
          requests:
            cpu: 100m
            memory: 100Mi
        securityContext:
          allowPrivilegeEscalation: false
      serviceAccountName: controller
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: autoscaler
    serving.knative.dev/release: "v0.11.0"
  name: autoscaler
  namespace: knative-serving
spec:
  ports:
  - name: http
    port: 8080
    protocol: TCP
    targetPort: 8080
  - name: http-metrics
    port: 9090
    protocol: TCP
    targetPort: 9090
  - name: https-custom-metrics
    port: 443
    protocol: TCP
    targetPort: 8443
  selector:
    app: autoscaler
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: autoscaler
  namespace: knative-serving
spec:
  replicas: 1
  selector:
    matchLabels:
      app: autoscaler
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
        sidecar.istio.io/inject: "true"
        traffic.sidecar.istio.io/includeInboundPorts: 8080,9090
      labels:
        app: autoscaler
        serving.knative.dev/release: "v0.11.0"
    spec:
      containers:
      - args:
        - --secure-port=8443
        - --cert-dir=/tmp
        env:
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: METRICS_DOMAIN
          value: knative.dev/serving
        image: gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler@sha256:e54439449a4c90934f5c9025914e798c21808237688d2b7edb961ca96942ad73
        livenessProbe:
          httpGet:
            httpHeaders:
            - name: k-kubelet-probe
              value: autoscaler
            path: /healthz
            port: 8080
        name: autoscaler
        ports:
        - containerPort: 8080
          name: websocket
        - containerPort: 9090
          name: metrics
        - containerPort: 8443
          name: custom-metrics
        - containerPort: 8008
          name: profiling
        readinessProbe:
          httpGet:
            httpHeaders:
            - name: k-kubelet-probe
              value: autoscaler
            path: /healthz
            port: 8080
        resources:
          limits:
            cpu: 300m
            memory: 400Mi
          requests:
            cpu: 30m
            memory: 40Mi
        securityContext:
          allowPrivilegeEscalation: false
      serviceAccountName: controller
---
apiVersion: v1
data:
  _example: ""
kind: ConfigMap
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: config-autoscaler
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: ""
kind: ConfigMap
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: config-defaults
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: ""
  queueSidecarImage: gcr.io/knative-releases/knative.dev/serving/cmd/queue@sha256:077d82a8f7b3f8c645e95abdf20acf1f1c5ea4d2215aa43ac707920914db5cf8
kind: ConfigMap
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: config-deployment
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: ""
kind: ConfigMap
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: config-domain
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: ""
kind: ConfigMap
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: config-gc
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: ""
kind: ConfigMap
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: config-logging
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: ""
kind: ConfigMap
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: config-network
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: ""
kind: ConfigMap
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: config-observability
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: ""
kind: ConfigMap
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: config-tracing
  namespace: knative-serving
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: controller
  namespace: knative-serving
spec:
  replicas: 1
  selector:
    matchLabels:
      app: controller
  template:
    metadata:
      annotations:
        sidecar.istio.io/inject: "false"
      labels:
        app: controller
        serving.knative.dev/release: "v0.11.0"
    spec:
      containers:
      - env:
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: METRICS_DOMAIN
          value: knative.dev/internal/serving
        image: gcr.io/knative-releases/knative.dev/serving/cmd/controller@sha256:1fefee2a41f33969ba0e2f398afcf0e308a0397b6b7d65d4b3630ab3229f764c
        name: controller
        ports:
        - containerPort: 9090
          name: metrics
        - containerPort: 8008
          name: profiling
        resources:
          limits:
            cpu: 1000m
            memory: 1000Mi
          requests:
            cpu: 10m
            memory: 10Mi
        securityContext:
          allowPrivilegeEscalation: false
      serviceAccountName: controller
---
apiVersion: apiregistration.k8s.io/v1beta1
kind: APIService
metadata:
  labels:
    autoscaling.knative.dev/metric-provider: custom-metrics
    serving.knative.dev/release: "v0.11.0"
  name: v1beta1.custom.metrics.k8s.io
spec:
  group: custom.metrics.k8s.io
  groupPriorityMinimum: 100
  insecureSkipTLSVerify: true
  service:
    name: autoscaler
    namespace: knative-serving
  version: v1beta1
  versionPriority: 100
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    serving.knative.dev/release: "v0.11.0"
  name: webhook
  namespace: knative-serving
spec:
  replicas: 1
  selector:
    matchLabels:
      app: webhook
      role: webhook
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
        sidecar.istio.io/inject: "false"
      labels:
        app: webhook
        role: webhook
        serving.knative.dev/release: "v0.11.0"
    spec:
      containers:
      - env:
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: METRICS_DOMAIN
          value: knative.dev/serving
        image: gcr.io/knative-releases/knative.dev/serving/cmd/webhook@sha256:b1f72e974058576faf5f62d984d2ce4edb18b12ae4a4cd673d3fffe7d7706837
        name: webhook
        ports:
        - containerPort: 9090
          name: metrics
        - containerPort: 8008
          name: profiling
        resources:
          limits:
            cpu: 200m
            memory: 200Mi
          requests:
            cpu: 20m
            memory: 20Mi
        securityContext:
          allowPrivilegeEscalation: false
      serviceAccountName: controller
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/controller: "true"
    serving.knative.dev/release: "v0.11.0"
  name: knative-serving-istio
rules:
- apiGroups:
  - networking.istio.io
  resources:
  - virtualservices
  - gateways
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
---
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  labels:
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: "v0.11.0"
  name: knative-ingress-gateway
  namespace: knative-serving
spec:
  selector:
    istio: ingressgateway
  servers:
  - hosts:
    - '*'
    port:
      name: http
      number: 80
      protocol: HTTP

---
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  labels:
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: "v0.11.0"
  name: cluster-local-gateway
  namespace: knative-serving
spec:
  selector:
    istio: cluster-local-gateway
  servers:
  - hosts:
    - '*'
    port:
      name: http
      number: 80
      protocol: HTTP

---
apiVersion: v1
data:
  _example: ""
kind: ConfigMap
metadata:
  labels:
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: "v0.11.0"
  name: config-istio
  namespace: knative-serving
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: "v0.11.0"
  name: networking-istio
  namespace: knative-serving
spec:
  replicas: 1
  selector:
    matchLabels:
      app: networking-istio
  template:
    metadata:
      annotations:
        sidecar.istio.io/inject: "false"
      labels:
        app: networking-istio
        serving.knative.dev/release: "v0.11.0"
    spec:
      containers:
      - env:
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: METRICS_DOMAIN
          value: knative.dev/serving
        image: gcr.io/knative-releases/knative.dev/serving/cmd/networking/istio@sha256:0c4565fe9f49fb5e91fd745ebbc3f1f75dfc78b74c34e0f462a9c89651b86fe2
        name: networking-istio
        ports:
        - containerPort: 9090
          name: metrics
        - containerPort: 8008
          name: profiling
        resources:
          limits:
            cpu: 1000m
            memory: 1000Mi
          requests:
            cpu: 10m
            memory: 10Mi
        securityContext:
          allowPrivilegeEscalation: false
      serviceAccountName: controller
